{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61f18df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters\n",
    "dataset_name = 'default' #'adult', 'bank', 'default', 'law'\n",
    "split = 'attr' #'attr'\n",
    "fairness_notion = 'stat_parity' #'eqop'\n",
    "num_clients = 3 #5, 10, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b79fd593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder,MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV,SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Input\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "# Importing necssary modules\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "from collections import Counter\n",
    "# Custom script \n",
    "#%matplotlibe inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "490a4660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import load_dataset, batch_data\n",
    "from utilities import *\n",
    "if split == 'random':\n",
    "    clients_batched, clients_test_data_batched, test_batched, p_Group, np_Group, sa_index, Xtr = load_dataset(dataset_name, split, num_clients)\n",
    "else:\n",
    "    clients_batched, client_data_testx, client_data_testy, test_batched, p_Group, np_Group, sa_index, Xtr = load_dataset(dataset_name, split, num_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e94cf90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72000\n",
      "24000\n"
     ]
    }
   ],
   "source": [
    "client_names = list(clients_batched.keys())\n",
    "bs = list(clients_batched[\"client_1\"])[0][0].shape[0] \n",
    "#first calculate the total training data points across clinets\n",
    "global_count = sum([tf.data.experimental.cardinality(clients_batched[client_name]).numpy() for client_name in client_names])*bs\n",
    "local_count = tf.data.experimental.cardinality(clients_batched['client_1']).numpy()*bs\n",
    "print(global_count) \n",
    "print(local_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d56ee0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Number of client datasets: {l}'.format(l=len(clients_batched)))\n",
    "#print('First dataset: {d}'.format(d=clients_batched['client_1']))\n",
    "#print('Number of client test datasets: {l}'.format(l=len(clients_test_data_batched)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9fd2115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,BatchNormalization,InputLayer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "class SimpleMLP:\n",
    "    @staticmethod\n",
    "    def build(x_train,n):\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(InputLayer(input_shape=(x_train.shape[1],)))\n",
    "        model.add(Dense(x_train.shape[1],activation='relu'))#,input_shape=(x_train.shape[1],)))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(n*x_train.shape[1],activation='relu'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(n*x_train.shape[1],activation='relu'))\n",
    "\n",
    "        model.add(Dense(1,activation='sigmoid'))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c1a8baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00001 #0.0001, 0.00001, 0.0001, a_age = 0.0001, b_age = 0.0001, d_age = 0.0001 \n",
    "comms_round = 50\n",
    "loss='binary_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "#optimizer = Adam(learning_rate=lr)\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b06b366",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_1\n",
      "bismillah\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 23:06:01.291011: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 272us/step\n",
      "balanced_accuracy_client 0.5558917177252604\n",
      "188/188 [==============================] - 0s 261us/step\n",
      "188/188 [==============================] - 0s 260us/step\n",
      "188/188 [==============================] - 0s 262us/step\n",
      "188/188 [==============================] - 0s 296us/step\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "1\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 266us/step\n",
      "balanced_accuracy_client 0.5702562500351837\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "188/188 [==============================] - 0s 260us/step\n",
      "188/188 [==============================] - 0s 262us/step\n",
      "188/188 [==============================] - 0s 260us/step\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "1\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 274us/step\n",
      "balanced_accuracy_client 0.5713054048397224\n",
      "188/188 [==============================] - 0s 270us/step\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "188/188 [==============================] - 0s 264us/step\n",
      "1\n",
      "563/563 [==============================] - 0s 258us/step\n",
      "comm_round: 0 | global_acc: 0.5628333333333333 | global_loss: 7.742783069610596\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 275us/step\n",
      "188/188 [==============================] - 0s 260us/step\n",
      "188/188 [==============================] - 0s 257us/step\n",
      "188/188 [==============================] - 0s 266us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 258us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "188/188 [==============================] - 0s 260us/step\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 266us/step\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 264us/step\n",
      "188/188 [==============================] - 0s 260us/step\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 298us/step\n",
      "188/188 [==============================] - 0s 258us/step\n",
      "188/188 [==============================] - 0s 261us/step\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "563/563 [==============================] - 0s 255us/step\n",
      "comm_round: 1 | global_acc: 0.5231666666666667 | global_loss: 8.341540336608887\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 274us/step\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "188/188 [==============================] - 0s 258us/step\n",
      "188/188 [==============================] - 0s 262us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 265us/step\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "188/188 [==============================] - 0s 262us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "188/188 [==============================] - 0s 258us/step\n",
      "188/188 [==============================] - 0s 262us/step\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "563/563 [==============================] - 0s 258us/step\n",
      "comm_round: 2 | global_acc: 0.5564444444444444 | global_loss: 7.945915699005127\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 268us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 262us/step\n",
      "188/188 [==============================] - 0s 264us/step\n",
      "188/188 [==============================] - 0s 261us/step\n",
      "188/188 [==============================] - 0s 332us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 262us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 262us/step\n",
      "3\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 262us/step\n",
      "188/188 [==============================] - 0s 261us/step\n",
      "188/188 [==============================] - 0s 262us/step\n",
      "188/188 [==============================] - 0s 262us/step\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 264us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 407us/step\n",
      "comm_round: 3 | global_acc: 0.5736666666666667 | global_loss: 7.727512836456299\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 296us/step\n",
      "188/188 [==============================] - 0s 272us/step\n",
      "188/188 [==============================] - 0s 261us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 267us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 305us/step\n",
      "3\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 283us/step\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "188/188 [==============================] - 0s 272us/step\n",
      "188/188 [==============================] - 0s 264us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "188/188 [==============================] - 0s 271us/step\n",
      "188/188 [==============================] - 0s 266us/step\n",
      "188/188 [==============================] - 0s 266us/step\n",
      "188/188 [==============================] - 0s 266us/step\n",
      "3\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 279us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 261us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 266us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 263us/step\n",
      "comm_round: 4 | global_acc: 0.6393333333333333 | global_loss: 6.926087379455566\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 283us/step\n",
      "188/188 [==============================] - 0s 266us/step\n",
      "188/188 [==============================] - 0s 271us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 267us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 275us/step\n",
      "188/188 [==============================] - 0s 264us/step\n",
      "188/188 [==============================] - 0s 266us/step\n",
      "188/188 [==============================] - 0s 269us/step\n",
      "3\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 266us/step\n",
      "188/188 [==============================] - 0s 270us/step\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 274us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 271us/step\n",
      "3\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 281us/step\n",
      "188/188 [==============================] - 0s 267us/step\n",
      "188/188 [==============================] - 0s 265us/step\n",
      "188/188 [==============================] - 0s 265us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 271us/step\n",
      "188/188 [==============================] - 0s 270us/step\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "188/188 [==============================] - 0s 271us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 262us/step\n",
      "comm_round: 5 | global_acc: 0.6352222222222222 | global_loss: 6.9649553298950195\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 296us/step\n",
      "188/188 [==============================] - 0s 265us/step\n",
      "188/188 [==============================] - 0s 277us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 273us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 270us/step\n",
      "188/188 [==============================] - 0s 273us/step\n",
      "3\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 280us/step\n",
      "188/188 [==============================] - 0s 265us/step\n",
      "188/188 [==============================] - 0s 272us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 265us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 264us/step\n",
      "3\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 277us/step\n",
      "188/188 [==============================] - 0s 270us/step\n",
      "188/188 [==============================] - 0s 270us/step\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 274us/step\n",
      "188/188 [==============================] - 0s 261us/step\n",
      "188/188 [==============================] - 0s 265us/step\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 261us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 259us/step\n",
      "comm_round: 6 | global_acc: 0.6352222222222222 | global_loss: 6.9649553298950195\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 266us/step\n",
      "188/188 [==============================] - 0s 260us/step\n",
      "188/188 [==============================] - 0s 262us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 876us/step\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 273us/step\n",
      "188/188 [==============================] - 0s 293us/step\n",
      "3\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 276us/step\n",
      "188/188 [==============================] - 0s 264us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 262us/step\n",
      "3\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 249us/step\n",
      "comm_round: 7 | global_acc: 0.6767777777777778 | global_loss: 6.399513244628906\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 266us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 246us/step\n",
      "3\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 233us/step\n",
      "188/188 [==============================] - 0s 257us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 245us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "3\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "563/563 [==============================] - 0s 254us/step\n",
      "comm_round: 8 | global_acc: 0.6883333333333334 | global_loss: 6.266250133514404\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 267us/step\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "3\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 257us/step\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 289us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 258us/step\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 257us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 258us/step\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 257us/step\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 257us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "188/188 [==============================] - 0s 258us/step\n",
      "188/188 [==============================] - 0s 257us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "563/563 [==============================] - 0s 248us/step\n",
      "comm_round: 9 | global_acc: 0.737 | global_loss: 5.703583240509033\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 264us/step\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 257us/step\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "2\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 255us/step\n",
      "comm_round: 10 | global_acc: 0.7465 | global_loss: 5.571708679199219\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 258us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 246us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 257us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "3\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 267us/step\n",
      "188/188 [==============================] - 0s 261us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 291us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 250us/step\n",
      "comm_round: 11 | global_acc: 0.7494444444444445 | global_loss: 5.539780616760254\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 279us/step\n",
      "188/188 [==============================] - 0s 272us/step\n",
      "188/188 [==============================] - 0s 260us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 257us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "3\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 260us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 261us/step\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 248us/step\n",
      "comm_round: 12 | global_acc: 0.7508888888888889 | global_loss: 5.522197723388672\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 261us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 257us/step\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "3\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 265us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 258us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 253us/step\n",
      "comm_round: 13 | global_acc: 0.7556666666666667 | global_loss: 5.426877498626709\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 273us/step\n",
      "188/188 [==============================] - 0s 245us/step\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "188/188 [==============================] - 0s 245us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "3\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 258us/step\n",
      "188/188 [==============================] - 0s 244us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 257us/step\n",
      "188/188 [==============================] - 0s 246us/step\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "WARNING:tensorflow:5 out of the last 22 calls to <function Model.make_test_function.<locals>.test_function at 0x168076f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 250us/step\n",
      "comm_round: 14 | global_acc: 0.7548333333333334 | global_loss: 5.4541778564453125\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 230us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "3\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 262us/step\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 257us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 251us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 244us/step\n",
      "comm_round: 15 | global_acc: 0.7496111111111111 | global_loss: 5.5541253089904785\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 258us/step\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 246us/step\n",
      "3\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 261us/step\n",
      "188/188 [==============================] - 0s 234us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "188/188 [==============================] - 0s 237us/step\n",
      "188/188 [==============================] - 0s 257us/step\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 257us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 247us/step\n",
      "comm_round: 16 | global_acc: 0.7497222222222222 | global_loss: 5.5624542236328125\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 239us/step\n",
      "188/188 [==============================] - 0s 240us/step\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 258us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "3\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "188/188 [==============================] - 0s 246us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 246us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 250us/step\n",
      "comm_round: 17 | global_acc: 0.7599444444444444 | global_loss: 5.444923400878906\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "188/188 [==============================] - 0s 246us/step\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 246us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 267us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 242us/step\n",
      "188/188 [==============================] - 0s 246us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 250us/step\n",
      "comm_round: 18 | global_acc: 0.7630555555555556 | global_loss: 5.442147731781006\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "188/188 [==============================] - 0s 242us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 242us/step\n",
      "188/188 [==============================] - 0s 245us/step\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 245us/step\n",
      "188/188 [==============================] - 0s 239us/step\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "188/188 [==============================] - 0s 244us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 243us/step\n",
      "comm_round: 19 | global_acc: 0.7631666666666667 | global_loss: 5.467133522033691\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 260us/step\n",
      "188/188 [==============================] - 0s 238us/step\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 236us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 258us/step\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 241us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 245us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 235us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 236us/step\n",
      "188/188 [==============================] - 0s 242us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 246us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 246us/step\n",
      "comm_round: 20 | global_acc: 0.7677222222222222 | global_loss: 5.39402437210083\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 238us/step\n",
      "188/188 [==============================] - 0s 244us/step\n",
      "188/188 [==============================] - 0s 239us/step\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 241us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 240us/step\n",
      "188/188 [==============================] - 0s 241us/step\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 243us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 251us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 251us/step\n",
      "comm_round: 21 | global_acc: 0.7674444444444445 | global_loss: 5.394486904144287\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 243us/step\n",
      "188/188 [==============================] - 0s 238us/step\n",
      "188/188 [==============================] - 0s 239us/step\n",
      "188/188 [==============================] - 0s 235us/step\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "188/188 [==============================] - 0s 246us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 241us/step\n",
      "188/188 [==============================] - 0s 240us/step\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "188/188 [==============================] - 0s 244us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 235us/step\n",
      "comm_round: 22 | global_acc: 0.7728888888888888 | global_loss: 5.336184501647949\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 271us/step\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "188/188 [==============================] - 0s 234us/step\n",
      "188/188 [==============================] - 0s 234us/step\n",
      "188/188 [==============================] - 0s 230us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 246us/step\n",
      "188/188 [==============================] - 0s 239us/step\n",
      "188/188 [==============================] - 0s 235us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 242us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 243us/step\n",
      "188/188 [==============================] - 0s 236us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 232us/step\n",
      "comm_round: 23 | global_acc: 0.7724444444444445 | global_loss: 5.3546929359436035\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "188/188 [==============================] - 0s 230us/step\n",
      "188/188 [==============================] - 0s 239us/step\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 237us/step\n",
      "188/188 [==============================] - 0s 233us/step\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 245us/step\n",
      "188/188 [==============================] - 0s 227us/step\n",
      "188/188 [==============================] - 0s 230us/step\n",
      "188/188 [==============================] - 0s 232us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 227us/step\n",
      "188/188 [==============================] - 0s 227us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 232us/step\n",
      "comm_round: 24 | global_acc: 0.7751111111111111 | global_loss: 5.326004505157471\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 264us/step\n",
      "188/188 [==============================] - 0s 241us/step\n",
      "188/188 [==============================] - 0s 242us/step\n",
      "188/188 [==============================] - 0s 242us/step\n",
      "188/188 [==============================] - 0s 239us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 243us/step\n",
      "188/188 [==============================] - 0s 238us/step\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "188/188 [==============================] - 0s 237us/step\n",
      "188/188 [==============================] - 0s 238us/step\n",
      "188/188 [==============================] - 0s 239us/step\n",
      "188/188 [==============================] - 0s 232us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 236us/step\n",
      "188/188 [==============================] - 0s 236us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 238us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 229us/step\n",
      "comm_round: 25 | global_acc: 0.7768888888888889 | global_loss: 5.293614387512207\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "188/188 [==============================] - 0s 233us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 238us/step\n",
      "188/188 [==============================] - 0s 244us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 241us/step\n",
      "188/188 [==============================] - 0s 229us/step\n",
      "188/188 [==============================] - 0s 246us/step\n",
      "188/188 [==============================] - 0s 232us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 241us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 242us/step\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 230us/step\n",
      "comm_round: 26 | global_acc: 0.7767222222222222 | global_loss: 5.308884143829346\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 240us/step\n",
      "188/188 [==============================] - 0s 242us/step\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "188/188 [==============================] - 0s 245us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 237us/step\n",
      "188/188 [==============================] - 0s 230us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "188/188 [==============================] - 0s 224us/step\n",
      "188/188 [==============================] - 0s 240us/step\n",
      "188/188 [==============================] - 0s 243us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 239us/step\n",
      "188/188 [==============================] - 0s 234us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 243us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 233us/step\n",
      "comm_round: 27 | global_acc: 0.7777777777777778 | global_loss: 5.301017761230469\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 241us/step\n",
      "188/188 [==============================] - 0s 238us/step\n",
      "188/188 [==============================] - 0s 241us/step\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 258us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 230us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 257us/step\n",
      "188/188 [==============================] - 0s 230us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 243us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 233us/step\n",
      "188/188 [==============================] - 0s 239us/step\n",
      "188/188 [==============================] - 0s 228us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 228us/step\n",
      "comm_round: 28 | global_acc: 0.7778888888888889 | global_loss: 5.3084211349487305\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 262us/step\n",
      "188/188 [==============================] - 0s 232us/step\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "188/188 [==============================] - 0s 240us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 257us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 226us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 243us/step\n",
      "188/188 [==============================] - 0s 237us/step\n",
      "188/188 [==============================] - 0s 230us/step\n",
      "188/188 [==============================] - 0s 225us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 243us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 238us/step\n",
      "188/188 [==============================] - 0s 226us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 232us/step\n",
      "comm_round: 29 | global_acc: 0.7780555555555555 | global_loss: 5.320914268493652\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 222us/step\n",
      "188/188 [==============================] - 0s 238us/step\n",
      "188/188 [==============================] - 0s 228us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 237us/step\n",
      "188/188 [==============================] - 0s 237us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 242us/step\n",
      "188/188 [==============================] - 0s 229us/step\n",
      "188/188 [==============================] - 0s 228us/step\n",
      "188/188 [==============================] - 0s 244us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 228us/step\n",
      "188/188 [==============================] - 0s 235us/step\n",
      "188/188 [==============================] - 0s 230us/step\n",
      "2\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "188/188 [==============================] - 0s 245us/step\n",
      "188/188 [==============================] - 0s 235us/step\n",
      "3\n",
      "563/563 [==============================] - 0s 229us/step\n",
      "comm_round: 30 | global_acc: 0.7775 | global_loss: 5.336647033691406\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 261us/step\n",
      "188/188 [==============================] - 0s 232us/step\n",
      "188/188 [==============================] - 0s 234us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 252us/step\n",
      "188/188 [==============================] - 0s 243us/step\n",
      "188/188 [==============================] - 0s 234us/step\n",
      "188/188 [==============================] - 0s 237us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 258us/step\n",
      "188/188 [==============================] - 0s 237us/step\n",
      "188/188 [==============================] - 0s 232us/step\n",
      "188/188 [==============================] - 0s 280us/step\n",
      "188/188 [==============================] - 0s 242us/step\n",
      "188/188 [==============================] - 0s 258us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 230us/step\n",
      "188/188 [==============================] - 0s 231us/step\n",
      "188/188 [==============================] - 0s 227us/step\n",
      "188/188 [==============================] - 0s 235us/step\n",
      "188/188 [==============================] - 0s 231us/step\n",
      "188/188 [==============================] - 0s 234us/step\n",
      "188/188 [==============================] - 0s 244us/step\n",
      "188/188 [==============================] - 0s 233us/step\n",
      "563/563 [==============================] - 0s 230us/step\n",
      "comm_round: 31 | global_acc: 0.7803888888888889 | global_loss: 5.319989204406738\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 260us/step\n",
      "188/188 [==============================] - 0s 226us/step\n",
      "188/188 [==============================] - 0s 218us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 236us/step\n",
      "188/188 [==============================] - 0s 240us/step\n",
      "188/188 [==============================] - 0s 231us/step\n",
      "188/188 [==============================] - 0s 239us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 237us/step\n",
      "188/188 [==============================] - 0s 244us/step\n",
      "188/188 [==============================] - 0s 240us/step\n",
      "188/188 [==============================] - 0s 235us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 227us/step\n",
      "188/188 [==============================] - 0s 246us/step\n",
      "563/563 [==============================] - 0s 229us/step\n",
      "comm_round: 32 | global_acc: 0.7813333333333333 | global_loss: 5.32230281829834\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 258us/step\n",
      "188/188 [==============================] - 0s 246us/step\n",
      "188/188 [==============================] - 0s 244us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 231us/step\n",
      "188/188 [==============================] - 0s 224us/step\n",
      "188/188 [==============================] - 0s 239us/step\n",
      "188/188 [==============================] - 0s 230us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 242us/step\n",
      "188/188 [==============================] - 0s 243us/step\n",
      "188/188 [==============================] - 0s 243us/step\n",
      "188/188 [==============================] - 0s 240us/step\n",
      "188/188 [==============================] - 0s 222us/step\n",
      "563/563 [==============================] - 0s 234us/step\n",
      "comm_round: 33 | global_acc: 0.7818888888888889 | global_loss: 5.3037943840026855\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 236us/step\n",
      "188/188 [==============================] - 0s 229us/step\n",
      "188/188 [==============================] - 0s 220us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "188/188 [==============================] - 0s 226us/step\n",
      "188/188 [==============================] - 0s 235us/step\n",
      "188/188 [==============================] - 0s 234us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "188/188 [==============================] - 0s 232us/step\n",
      "188/188 [==============================] - 0s 235us/step\n",
      "188/188 [==============================] - 0s 260us/step\n",
      "188/188 [==============================] - 0s 236us/step\n",
      "1\n",
      "188/188 [==============================] - 0s 235us/step\n",
      "188/188 [==============================] - 0s 238us/step\n",
      "563/563 [==============================] - 0s 228us/step\n",
      "comm_round: 34 | global_acc: 0.7821111111111111 | global_loss: 5.3093461990356445\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 277us/step\n",
      "188/188 [==============================] - 0s 234us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "188/188 [==============================] - 0s 231us/step\n",
      "188/188 [==============================] - 0s 231us/step\n",
      "188/188 [==============================] - 0s 235us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 244us/step\n",
      "188/188 [==============================] - 0s 228us/step\n",
      "188/188 [==============================] - 0s 229us/step\n",
      "188/188 [==============================] - 0s 240us/step\n",
      "563/563 [==============================] - 0s 233us/step\n",
      "comm_round: 35 | global_acc: 0.7825555555555556 | global_loss: 5.3093461990356445\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "188/188 [==============================] - 0s 234us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 244us/step\n",
      "188/188 [==============================] - 0s 231us/step\n",
      "188/188 [==============================] - 0s 225us/step\n",
      "188/188 [==============================] - 0s 229us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 264us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 245us/step\n",
      "188/188 [==============================] - 0s 229us/step\n",
      "563/563 [==============================] - 0s 258us/step\n",
      "comm_round: 36 | global_acc: 0.7829444444444444 | global_loss: 5.306107521057129\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 266us/step\n",
      "188/188 [==============================] - 0s 239us/step\n",
      "188/188 [==============================] - 0s 235us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 260us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 246us/step\n",
      "188/188 [==============================] - 0s 231us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 246us/step\n",
      "188/188 [==============================] - 0s 229us/step\n",
      "188/188 [==============================] - 0s 245us/step\n",
      "563/563 [==============================] - 0s 230us/step\n",
      "comm_round: 37 | global_acc: 0.7831666666666667 | global_loss: 5.30333137512207\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 245us/step\n",
      "188/188 [==============================] - 0s 234us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 244us/step\n",
      "188/188 [==============================] - 0s 235us/step\n",
      "188/188 [==============================] - 0s 224us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 257us/step\n",
      "188/188 [==============================] - 0s 244us/step\n",
      "188/188 [==============================] - 0s 244us/step\n",
      "188/188 [==============================] - 0s 245us/step\n",
      "563/563 [==============================] - 0s 239us/step\n",
      "comm_round: 38 | global_acc: 0.7836666666666666 | global_loss: 5.307495594024658\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 244us/step\n",
      "188/188 [==============================] - 0s 237us/step\n",
      "188/188 [==============================] - 0s 246us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 234us/step\n",
      "188/188 [==============================] - 0s 224us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 227us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "563/563 [==============================] - 0s 242us/step\n",
      "comm_round: 39 | global_acc: 0.7836111111111111 | global_loss: 5.312585353851318\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 256us/step\n",
      "188/188 [==============================] - 0s 236us/step\n",
      "188/188 [==============================] - 0s 227us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 257us/step\n",
      "188/188 [==============================] - 0s 234us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 245us/step\n",
      "188/188 [==============================] - 0s 238us/step\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x179420dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "188/188 [==============================] - 0s 231us/step\n",
      "563/563 [==============================] - 0s 231us/step\n",
      "comm_round: 40 | global_acc: 0.7822777777777777 | global_loss: 5.332019805908203\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 267us/step\n",
      "188/188 [==============================] - 0s 236us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 235us/step\n",
      "188/188 [==============================] - 0s 235us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 227us/step\n",
      "188/188 [==============================] - 0s 235us/step\n",
      "563/563 [==============================] - 0s 241us/step\n",
      "comm_round: 41 | global_acc: 0.7834444444444445 | global_loss: 5.320451736450195\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "188/188 [==============================] - 0s 229us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 240us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 227us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 242us/step\n",
      "188/188 [==============================] - 0s 243us/step\n",
      "563/563 [==============================] - 0s 227us/step\n",
      "comm_round: 42 | global_acc: 0.7863333333333333 | global_loss: 5.264925479888916\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "188/188 [==============================] - 0s 238us/step\n",
      "188/188 [==============================] - 0s 226us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 239us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "188/188 [==============================] - 0s 234us/step\n",
      "563/563 [==============================] - 0s 229us/step\n",
      "comm_round: 43 | global_acc: 0.7837222222222222 | global_loss: 5.318138122558594\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 260us/step\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "188/188 [==============================] - 0s 244us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 235us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "188/188 [==============================] - 0s 231us/step\n",
      "188/188 [==============================] - 0s 246us/step\n",
      "563/563 [==============================] - 0s 238us/step\n",
      "comm_round: 44 | global_acc: 0.7790555555555555 | global_loss: 5.394949436187744\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 261us/step\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "188/188 [==============================] - 0s 229us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 266us/step\n",
      "188/188 [==============================] - 0s 233us/step\n",
      "188/188 [==============================] - 0s 238us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 244us/step\n",
      "188/188 [==============================] - 0s 238us/step\n",
      "563/563 [==============================] - 0s 239us/step\n",
      "comm_round: 45 | global_acc: 0.7823888888888889 | global_loss: 5.332019805908203\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 246us/step\n",
      "188/188 [==============================] - 0s 238us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 245us/step\n",
      "188/188 [==============================] - 0s 251us/step\n",
      "188/188 [==============================] - 0s 242us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 254us/step\n",
      "188/188 [==============================] - 0s 246us/step\n",
      "188/188 [==============================] - 0s 230us/step\n",
      "563/563 [==============================] - 0s 248us/step\n",
      "comm_round: 46 | global_acc: 0.7780555555555555 | global_loss: 5.406980991363525\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 279us/step\n",
      "188/188 [==============================] - 0s 263us/step\n",
      "188/188 [==============================] - 0s 249us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 259us/step\n",
      "188/188 [==============================] - 0s 241us/step\n",
      "188/188 [==============================] - 0s 237us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 255us/step\n",
      "188/188 [==============================] - 0s 242us/step\n",
      "563/563 [==============================] - 0s 229us/step\n",
      "comm_round: 47 | global_acc: 0.7827222222222222 | global_loss: 5.340348720550537\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 255us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 248us/step\n",
      "188/188 [==============================] - 0s 230us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 248us/step\n",
      "188/188 [==============================] - 0s 236us/step\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 253us/step\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 260us/step\n",
      "563/563 [==============================] - 0s 240us/step\n",
      "comm_round: 48 | global_acc: 0.7771111111111111 | global_loss: 5.422250270843506\n",
      "x_test 18000 \n",
      "client_1\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 270us/step\n",
      "188/188 [==============================] - 0s 250us/step\n",
      "188/188 [==============================] - 0s 238us/step\n",
      "client_2\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 779us/step\n",
      "188/188 [==============================] - 0s 390us/step\n",
      "188/188 [==============================] - 0s 262us/step\n",
      "1\n",
      "client_3\n",
      "bismillah\n",
      "188/188 [==============================] - 0s 247us/step\n",
      "188/188 [==============================] - 0s 238us/step\n",
      "563/563 [==============================] - 0s 233us/step\n",
      "comm_round: 49 | global_acc: 0.7821666666666667 | global_loss: 5.350528717041016\n",
      "x_test 18000 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "smlp_global = SimpleMLP()\n",
    "num_layers_mult=1\n",
    "n=num_layers_mult\n",
    "comms_round = 50\n",
    "global_model = smlp_global.build(Xtr,n)\n",
    "sensitivity_= []\n",
    "specificity_= []\n",
    "BalanceACC_= []\n",
    "G_mean_= []\n",
    "FP_rate_= []\n",
    "FN_rate_= []\n",
    "assigned_positives = 0\n",
    "total_positives = 0\n",
    "accuracy_= []\n",
    "loss_= []\n",
    "statistical_parity_ = []\n",
    "eqop_ = []\n",
    "disc_thresh = 0.005\n",
    "lambda_initial = 0.005 #0.005,0.005, 0.008, a_age = 0.05\n",
    "disc_tolerance = 0.1 #0.005,0.1\n",
    "epsilon=1\n",
    "pp_group = p_Group\n",
    "npp_group=np_Group\n",
    "#commence global training loop\n",
    "import time\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "destination = \"./\"\n",
    "start = time.time()\n",
    "end_time = []\n",
    "e=EarlyStopping(patience=5,restore_best_weights=True)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "for comm_round in range(comms_round):\n",
    "            \n",
    "    # get the global model's weights - will serve as the initial weights for all local models\n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    #initial list to collect local model weights after scalling\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    #randomize client data - using keys\n",
    "    client_names= list(clients_batched.keys())\n",
    "    #random.shuffle(client_names)\n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    client_number=0\n",
    "    for client in client_names:   \n",
    "        smlp_local = SimpleMLP()\n",
    "        local_model = smlp_local.build(Xtr, n)\n",
    "        local_model.compile(loss=loss, \n",
    "                      optimizer=optimizer, \n",
    "                      metrics=metrics)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #set local model weight to the weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        #here we should get the traning data from clients and try to do ksmote and see changes\n",
    "       \n",
    "        xxte = [] ##?client data?\n",
    "        yte = []\n",
    "        \n",
    "        for(X_test, Y_test) in clients_batched[client]:\n",
    "            \n",
    "            i = 0\n",
    "            while (i <len(X_test)):       \n",
    "                xxte.append(X_test[i].numpy())  \n",
    "                yte.append(Y_test[i].numpy())\n",
    "                i +=1\n",
    "        print(client)\n",
    "        #print(\"length of dataset: %s\" %len(xxte))\n",
    "        if split=='random':\n",
    "            x_test_client = []\n",
    "            y_test_client = []\n",
    "            for(X_test_real, Y_test_real) in clients_test_data_batched[client]:\n",
    "                i = 0\n",
    "                while (i <len(X_test_real)):       \n",
    "                    x_test_client.append(X_test_real[i].numpy())  \n",
    "                    y_test_client.append(Y_test_real[i].numpy())\n",
    "                    i +=1\n",
    "        \n",
    "            x_test_client = np.array(x_test_client)\n",
    "        \n",
    "            y_test_client = np.array(y_test_client)\n",
    "        else:\n",
    "            y_test_client = client_data_testy[client_number]\n",
    "            x_test_client = client_data_testx[client_number]\n",
    "            #test_batched = tf.data.Dataset.from_tensor_slices((x_test_client, y_test_client)).batch(len(y_test_client))\n",
    "       \n",
    "        client_number+=1\n",
    "        \n",
    "        \n",
    "   \n",
    "        minority_label = 1\n",
    "        majority_label = 0\n",
    "        \n",
    "        print(\"bismillah\")\n",
    "        if comm_round == 0:\n",
    "            Xtr_1_new=np.array(xxte)\n",
    "            Ytr_1_new=np.array(yte)\n",
    "              \n",
    "                    \n",
    "            Xtr_1_new = np.array(Xtr_1_new)\n",
    "            Ytr_1_new = np.array(Ytr_1_new)\n",
    "            added_points = len(Xtr_1_new) - len(xxte)\n",
    "            \n",
    "            #new batch for new data\n",
    "            #split data for validation set\n",
    "            Xtr_1_new_split,x_val,Ytr_1_new_split,y_val=train_test_split(Xtr_1_new,Ytr_1_new,test_size=0.10,shuffle=True)\n",
    "        \n",
    "            data = list(zip(Xtr_1_new_split, Ytr_1_new_split))\n",
    "            random.shuffle(data)\n",
    "            btach_data = batch_data(data, bs=30)  \n",
    "            \n",
    "            class_weights=find_class_Weight(Ytr_1_new, majority_label,minority_label)\n",
    "            local_model.fit(btach_data,validation_data=(x_val,y_val),validation_steps=1, callbacks=[e], epochs=3, verbose=0, \n",
    "                            class_weight=class_weights)\n",
    "            \n",
    "            pp_group = p_Group\n",
    "            npp_group=np_Group\n",
    "            disc_score, assigned_positives, total_positives, balanced_accuracy_client = test_client_model(x_test_client, y_test_client,  local_model,pp_group,npp_group, sa_index, fairness_notion)\n",
    "            print(\"balanced_accuracy_client %s\" % balanced_accuracy_client)\n",
    "            if disc_score<0:\n",
    "                pp_group = np_Group\n",
    "                npp_group=p_Group\n",
    "                disc_score, assigned_positives, total_positives, balanced_accuracy_client = test_client_model(x_test_client, y_test_client,  local_model,pp_group,npp_group,  sa_index, fairness_notion)\n",
    "            else:\n",
    "                pp_group = p_Group\n",
    "                npp_group=np_Group\n",
    "            trade_off = (1+epsilon**2)*((balanced_accuracy_client*(1-abs(disc_score)))/(epsilon*balanced_accuracy_client+(1-abs(disc_score))))\n",
    "            lambda_score = lambda_initial*(1+(disc_score/disc_tolerance))\n",
    "            \n",
    "        \n",
    "        if comm_round!=0:\n",
    "            pp_group = p_Group\n",
    "            npp_group=np_Group\n",
    "            disc_score, assigned_positives, total_positives, balanced_accuracy_client = test_client_model(x_test_client, y_test_client,  local_model,pp_group,npp_group,  sa_index, fairness_notion)\n",
    "            if disc_score<0:\n",
    "                pp_group = np_Group\n",
    "                npp_group=p_Group\n",
    "                disc_score, assigned_positives, total_positives, balanced_accuracy_client = test_client_model(x_test_client, y_test_client,  local_model,pp_group,npp_group,  sa_index, fairness_notion)\n",
    "            else:\n",
    "                pp_group = p_Group\n",
    "                npp_group=np_Group\n",
    "            trade_off = (1+epsilon**2)*((balanced_accuracy_client*(1-abs(disc_score)))/(epsilon*balanced_accuracy_client+(1-abs(disc_score))))\n",
    "        \n",
    "        if disc_score > disc_thresh:\n",
    "            \n",
    "      \n",
    "                prev_xtr,prev_ytr=[],[]\n",
    "                prev_disc_score= []\n",
    "                prev_trade_off=[]\n",
    "                lambda_score = lambda_initial*(1+(disc_score/disc_tolerance))\n",
    "                greater_disc_score = 0\n",
    "                min_disc_score =disc_score\n",
    "                max_trade_off = trade_off\n",
    "                Xtr_1_new=np.array(xxte)\n",
    "                Ytr_1_new=np.array(yte)\n",
    "                prev_xtr,prev_ytr = Xtr_1_new, Ytr_1_new\n",
    "                class_weights=find_class_Weight(Ytr_1_new, majority_label,minority_label)\n",
    "                points = len(Xtr_1_new) - len(xxte)\n",
    "                itr = 0\n",
    "                \n",
    "                while disc_score > disc_thresh:\n",
    "                    itr+=1\n",
    "                    closest_to_zero = min(disc_score, min_disc_score, key=abs)\n",
    "                    if trade_off>max_trade_off:\n",
    "                    #if closest_to_zero != min_disc_score:\n",
    "                        min_disc_score = disc_score\n",
    "                        max_trade_off = trade_off\n",
    "                        prev_xtr,prev_ytr = Xtr_1_new, Ytr_1_new\n",
    "                        points = len(Xtr_1_new) - len(xxte)\n",
    "                        local_model.save_weights('./checkpoints/my_checkpoint')\n",
    "                    if assigned_positives<= total_positives:\n",
    "                        \n",
    "                        #dmin_p_x, dmin_np_x, dmaj_p_x, dmaj_np_x = get_statistics(Xtr_1_new,Ytr_1_new,minority_label,majority_label)\n",
    "                        #N(C+,S) =N(C+,S)+ N(C,S)\n",
    "                        Xtr_min_p_new,Ytr_min_p_new = create_synth_data(xxte, yte, minority_label,majority_label,5,lambda_score,'min_p',pp_group,npp_group, sa_index)\n",
    "                    \n",
    "                        #N(C,S) =N(C,S) N(C,S)\n",
    "                        Xtr_maj_p_new,Ytr_maj_p_new = downsample(xxte, yte, minority_label,majority_label,5,lambda_score,'maj_p',pp_group,npp_group, sa_index)    \n",
    "                        \n",
    "                        for k in Xtr_maj_p_new:\n",
    "                            Xtr_min_p_new.append(k)\n",
    "                        for k in Ytr_maj_p_new:\n",
    "                            Ytr_min_p_new.append(k)\n",
    "                        \n",
    "                        Xtr_1_new = np.array(Xtr_min_p_new)\n",
    "                        Ytr_1_new = np.array(Ytr_min_p_new)\n",
    "                        #dmin_p_x2, dmin_np_x2, dmaj_p_x2, dmaj_np_x2 = get_statistics(Xtr_1_new,Ytr_1_new,minority_label,majority_label)\n",
    "                         \n",
    "                    else:\n",
    "                        #dmin_p_x, dmin_np_x, dmaj_p_x, dmaj_np_x = get_statistics(Xtr_1_new,Ytr_1_new,minority_label,majority_label)\n",
    "                        #N(C,S+) =N(C,S+)+ N(C+,S+)\n",
    "                        Xtr_maj_np_new,Ytr_maj_np_new = create_synth_data(xxte, yte, minority_label,majority_label,5,lambda_score,'maj_np',pp_group,npp_group, sa_index)\n",
    "                    \n",
    "                        #N(C+,S+) =N(C+,S+) N(C+,S+)\n",
    "                        Xtr_min_np_new,Ytr_min_np_new = downsample(xxte, yte, minority_label,majority_label,5,lambda_score,'min_np',pp_group,npp_group, sa_index)\n",
    "                        \n",
    "                        for k in Xtr_min_np_new:\n",
    "                            Xtr_maj_np_new.append(k)\n",
    "                        for k in Ytr_min_np_new:\n",
    "                            Ytr_maj_np_new.append(k)\n",
    "                        \n",
    "                        Xtr_1_new = np.array(Xtr_maj_np_new)\n",
    "                        Ytr_1_new = np.array(Ytr_maj_np_new)\n",
    "                       \n",
    "                    added_points = len(Xtr_1_new) - len(xxte)\n",
    "                    #new batch for new data\n",
    "                    #split data for validation set\n",
    "                    Xtr_1_new_split,x_val,Ytr_1_new_split,y_val=train_test_split(Xtr_1_new,Ytr_1_new,test_size=0.10,shuffle=True)\n",
    "                    \n",
    "                    data = list(zip(Xtr_1_new_split, Ytr_1_new_split))\n",
    "                    random.shuffle(data)\n",
    "                    btach_data = batch_data(data, bs=30)  \n",
    "                    #fit local model with client's data\n",
    "                    #create validation data and early stop\n",
    "                    \n",
    "                    local_model.fit(btach_data,validation_data=(x_val,y_val),validation_steps=1, callbacks=[e], epochs=3, verbose=0,\n",
    "                                    class_weight = class_weights)\n",
    "                    \n",
    "                    disc_score, assigned_positives, total_positives, balanced_accuracy_client = test_client_model(x_test_client, y_test_client,  local_model,pp_group,npp_group,  sa_index, fairness_notion)\n",
    "                    \n",
    "                    trade_off = (1+epsilon**2)*((balanced_accuracy_client*(1-abs(disc_score)))/(epsilon*balanced_accuracy_client+(1-abs(disc_score))))\n",
    "                    \n",
    "                    closest_to_zero = min(disc_score, min_disc_score, key=abs)\n",
    "                    if trade_off>max_trade_off:\n",
    "                    \n",
    "                        \n",
    "                        min_disc_score = disc_score\n",
    "                        max_trade_off = trade_off\n",
    "                        prev_xtr,prev_ytr = Xtr_1_new, Ytr_1_new\n",
    "                        points = len(Xtr_1_new) - len(xxte)\n",
    "                        local_model.save_weights('./checkpoints/my_checkpoint')\n",
    "               \n",
    "                    if len(prev_trade_off)>0:\n",
    "                       \n",
    "                        if trade_off<prev_trade_off[-1]:\n",
    "                            greater_disc_score+=1\n",
    "                            print(greater_disc_score)\n",
    "                            if greater_disc_score >2:\n",
    "                                local_model.load_weights('./checkpoints/my_checkpoint')\n",
    "                                added_points = points\n",
    "                                break\n",
    "                     \n",
    "                \n",
    "                    prev_trade_off.append(trade_off)\n",
    "                    xxte, yte = Xtr_1_new, Ytr_1_new\n",
    "                \n",
    "                xxtee=[]\n",
    "                ytee=[]\n",
    "                dataset = tf.data.Dataset.from_tensor_slices((list(prev_xtr), list(prev_ytr)))\n",
    "                up_dict = {client:batch_data(dataset)}\n",
    "                clients_batched.update(up_dict)\n",
    "                #clients_batched[client_name] = batch_data(dataset)\n",
    "                for(X_test, Y_test) in clients_batched[client]:\n",
    "            \n",
    "                    i = 0\n",
    "                    while (i <len(X_test)):       \n",
    "                        xxtee.append(X_test[i].numpy())  \n",
    "                        ytee.append(Y_test[i].numpy())\n",
    "                        i +=1 \n",
    "                \n",
    "        else:\n",
    "          \n",
    "            if comm_round!=0:\n",
    "                Xtr_1_new=np.array(xxte)\n",
    "                Ytr_1_new=np.array(yte)\n",
    "                #class_weights = class_weight.compute_class_weight('balanced',\n",
    "                #                                 np.unique(Ytr_1_new),\n",
    "                #                                 Ytr_1_new)\n",
    "                #class_weights = {majority_label:1, minority_label:7}\n",
    "                class_weights=find_class_Weight(Ytr_1_new, majority_label,minority_label)\n",
    "                Xtr_1_new,x_val,Ytr_1_new,y_val=train_test_split(Xtr_1_new,Ytr_1_new,test_size=0.10,shuffle=True)\n",
    "                data = list(zip(Xtr_1_new,Ytr_1_new))\n",
    "                #random.shuffle(data)\n",
    "                added_points = 0\n",
    "                btach_data = batch_data(data, bs=30)\n",
    "                \n",
    "                local_model.fit(btach_data,validation_data=(x_val,y_val),validation_steps = 1, callbacks=[e], epochs=3, \n",
    "                                verbose=0, class_weight = class_weights)\n",
    "        \n",
    "        #scale the model weights and add to list       \n",
    "        client_names = list(clients_batched.keys())\n",
    "        bs = list(clients_batched[client])[0][0].shape[0]\n",
    "        #first calculate the total training data points across clinets\n",
    "        global_count = sum([tf.data.experimental.cardinality(clients_batched[client_name]).numpy() for client_name in client_names])*bs\n",
    "        global_count = global_count + (added_points)\n",
    "        # get the total number of data points held by a client\n",
    "        local_count = len(Xtr_1_new)\n",
    "        scaling_factor = local_count/global_count\n",
    "                \n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "        \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    #update global model \n",
    "    \n",
    "    global_model.set_weights(average_weights)\n",
    "    \n",
    "    #test global model and print out metrics after each communications round\n",
    "    for(X_test, Y_test) in test_batched:\n",
    "        global_acc, global_loss,conf,stat_parity,eqop = test_model(X_test,Y_test, p_Group, np_Group,  sa_index, global_model, comm_round)\n",
    "        print(\"x_test %s \"% len(X_test))\n",
    "        TN = conf[0][0]\n",
    "        FP = conf[0][1]\n",
    "        FN = conf[1][0]\n",
    "        TP = conf[1][1]\n",
    "        sensitivity = TP/(TP+FN) \n",
    "        specificity = TN/(FP+TN)\n",
    "        \n",
    "        BalanceACC = (sensitivity+specificity)/2\n",
    "        G_mean = math.sqrt(sensitivity*specificity)\n",
    "        FN_rate= FN/(FN+TP) \n",
    "        FP_rate = FP/(FP+TN) \n",
    "        #add the data to arrays\n",
    "        sensitivity_.append(sensitivity)\n",
    "        specificity_.append(specificity)\n",
    "        BalanceACC_.append(BalanceACC)\n",
    "        G_mean_.append(G_mean)\n",
    "        FP_rate_.append(FP_rate)\n",
    "        FN_rate_.append(FN_rate)\n",
    "        accuracy_.append(global_acc)\n",
    "        loss_.append(global_loss)\n",
    "        statistical_parity_.append(stat_parity)\n",
    "        eqop_.append(eqop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3823c312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6848780135007952\n",
      "0.0019963075164443622\n",
      "-0.030892696366799588\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54cd645b",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
